{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNKp0mFa4x0nmnA2tjS3tkp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Spike sorting\n","\n","Ready to move on? Let's try to figure out what we have in terms of action potentials. Extracting action potentials from multielectrode voltage traces, and assigning them to specific neurons, has long been more art than science. One reason is that ground truth is generally not available, so quantifying whether one algorithm performs better than another has been difficult. Also, traditionally, different spike sorters have required input data in slightly different formats, and presented their results in different formats. Format conversion is not hard, but unpleasant enough that unbiased and quantitative comparison has been rare. And spike sorting is a slow process, so running lots of spike sorters on your data requires a real commitment of time.\n","\n","Faster computers and the publication of a generalized interface to spike sorting have improved the situation recently. In this exercise, you will feed a section of our data into one modern spike sorter, then compare your results with other students who used different sorters."],"metadata":{"id":"RJ61TJjpFgCC"}},{"cell_type":"markdown","source":["## Installing the sorter and the generalized interface\n","\n","The wrapper software is called \"spikeinterface\" (https://elifesciences.org/articles/61834) and is just one pip away:"],"metadata":{"id":"seq47cgBG3DC"}},{"cell_type":"code","source":["!pip install spikeinterface"],"metadata":{"id":"kRAMnJOKHFbh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689283515665,"user_tz":420,"elapsed":6048,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}},"outputId":"15e69b98-d373-4248-9691-66a78273edc0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spikeinterface\n","  Downloading spikeinterface-0.98.0-py3-none-any.whl (747 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m747.9/747.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spikeinterface) (1.22.4)\n","Collecting neo>=0.11.1 (from spikeinterface)\n","  Downloading neo-0.12.0-py3-none-any.whl (586 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from spikeinterface) (1.3.1)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from spikeinterface) (3.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spikeinterface) (4.65.0)\n","Collecting probeinterface>=0.2.16 (from spikeinterface)\n","  Downloading probeinterface-0.2.17-py3-none-any.whl (36 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from neo>=0.11.1->spikeinterface) (23.1)\n","Collecting quantities>=0.14.1 (from neo>=0.11.1->spikeinterface)\n","  Downloading quantities-0.14.1-py3-none-any.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: quantities, probeinterface, neo, spikeinterface\n","Successfully installed neo-0.12.0 probeinterface-0.2.17 quantities-0.14.1 spikeinterface-0.98.0\n"]}]},{"cell_type":"markdown","source":["It comes pre-configured with just a few spike sorters:"],"metadata":{"id":"-GmFe8IKHD_J"}},{"cell_type":"code","source":["import spikeinterface.sorters as ss\n","ss.installed_sorters()"],"metadata":{"id":"whR0SX4OHNyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689283517304,"user_tz":420,"elapsed":1643,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}},"outputId":"d3631601-6537-4597-fb5a-24767ec9800f"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['spykingcircus2', 'tridesclous2']"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["but we can easily install several more:"],"metadata":{"id":"GZy1b9IsHiiU"}},{"cell_type":"code","source":["!pip install herdingspikes\n","!pip install mountainsort5"],"metadata":{"id":"7T-_LwxjISz7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689283684947,"user_tz":420,"elapsed":65353,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}},"outputId":"86783fee-490f-4d9d-8fa0-d0bc6ba6d2ac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting herdingspikes\n","  Downloading herdingspikes-0.3.102.tar.gz (458 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/458.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m450.6/458.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.3/458.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from herdingspikes) (3.8.0)\n","Requirement already satisfied: matplotlib>=2.0 in /usr/local/lib/python3.10/dist-packages (from herdingspikes) (3.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from herdingspikes) (1.5.3)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from herdingspikes) (1.2.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from herdingspikes) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from herdingspikes) (1.16.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0->herdingspikes) (2.8.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->herdingspikes) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->herdingspikes) (3.1.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->herdingspikes) (2022.7.1)\n","Building wheels for collected packages: herdingspikes\n","  Building wheel for herdingspikes (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for herdingspikes: filename=herdingspikes-0.3.102-cp310-cp310-linux_x86_64.whl size=1412247 sha256=d3ba9a1db8a30b909d63d5f99b6b9bba13d34537b6affbdd11914561b34ea963\n","  Stored in directory: /root/.cache/pip/wheels/72/1e/b9/c5dd3284ac5c9d98a94b374b46518ec955ad1d3c396900041c\n","Successfully built herdingspikes\n","Installing collected packages: herdingspikes\n","Successfully installed herdingspikes-0.3.102\n","Collecting mountainsort5\n","  Downloading mountainsort5-0.3.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: spikeinterface>=0.97.1 in /usr/local/lib/python3.10/dist-packages (from mountainsort5) (0.98.0)\n","Collecting isosplit6>=0.1.0 (from mountainsort5)\n","  Downloading isosplit6-0.1.2.tar.gz (25 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mountainsort5) (1.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spikeinterface>=0.97.1->mountainsort5) (1.22.4)\n","Requirement already satisfied: neo>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from spikeinterface>=0.97.1->mountainsort5) (0.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from spikeinterface>=0.97.1->mountainsort5) (1.3.1)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from spikeinterface>=0.97.1->mountainsort5) (3.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spikeinterface>=0.97.1->mountainsort5) (4.65.0)\n","Requirement already satisfied: probeinterface>=0.2.16 in /usr/local/lib/python3.10/dist-packages (from spikeinterface>=0.97.1->mountainsort5) (0.2.17)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mountainsort5) (1.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from neo>=0.11.1->spikeinterface>=0.97.1->mountainsort5) (23.1)\n","Requirement already satisfied: quantities>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from neo>=0.11.1->spikeinterface>=0.97.1->mountainsort5) (0.14.1)\n","Building wheels for collected packages: isosplit6\n","  Building wheel for isosplit6 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for isosplit6: filename=isosplit6-0.1.2-cp310-cp310-linux_x86_64.whl size=100665 sha256=269fd5944b6e2abe94d39723eb0ad2846a7a4c928ce470326bc06af46144f565\n","  Stored in directory: /root/.cache/pip/wheels/a8/60/08/fcb17c25dcde09633bb20fca13a520d9f88485881fc35a3166\n","Successfully built isosplit6\n","Installing collected packages: isosplit6, mountainsort5\n","Successfully installed isosplit6-0.1.2 mountainsort5-0.3.0\n"]}]},{"cell_type":"markdown","source":["The standard invocation for importing spikeinterface is a little elaborate:"],"metadata":{"id":"X534iG-hHkuk"}},{"cell_type":"code","source":["import spikeinterface as si\n","import spikeinterface.extractors as se\n","import spikeinterface.preprocessing as spre\n","import spikeinterface.sorters as ss\n","import spikeinterface.postprocessing as spost\n","import spikeinterface.qualitymetrics as sqm\n","import spikeinterface.comparison as sc\n","import spikeinterface.exporters as sexp\n","import spikeinterface.widgets as sw\n","from probeinterface import Probe\n","from probeinterface.plotting import plot_probe\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from pathlib import Path\n"],"metadata":{"id":"tCeavzbnIe9g","executionInfo":{"status":"ok","timestamp":1689283692211,"user_tz":420,"elapsed":7270,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Loading data into spikeinterface\n","\n","Loading raw data into spikeinterface is straightforward, though I had to jump through some hoops to make it load our SALPA-preprocessed data. Check out the \"SI Hoops\" notebook for details. It also teaches you how to tell spikeinterface about the geometry of the Neuropixels probe."],"metadata":{"id":"PlKYBtLFIxey"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!ls /content/drive/MyDrive/datasai-daw"],"metadata":{"id":"O0eVlvE4Ja6Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689283710853,"user_tz":420,"elapsed":18653,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}},"outputId":"438fd9c2-e084-4c1e-8195-47c344be52bc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","data  notebooks  __pycache__  vizly.py\n"]}]},{"cell_type":"code","source":["root = \"/content/drive/MyDrive/datasai-daw/data/2021-07-20_11-59-01\"\n","src = Path(root) / \"Record Node 115\""],"metadata":{"id":"zDjIHsD3JhnT","executionInfo":{"status":"ok","timestamp":1689283767261,"user_tz":420,"elapsed":207,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["To load the raw data, you would do:\n","\n","    rec = se.read_openephys(src, stream_name=\"Record Node 115#Neuropix-PXI-111.0\")\n","\n","However, we will read the pre-processed data:"],"metadata":{"id":"l439Ag1UJstb"}},{"cell_type":"code","source":["rec = si.load_extractor(src / \"salpa\")"],"metadata":{"id":"aboOWGPLJs5h","executionInfo":{"status":"ok","timestamp":1689283783548,"user_tz":420,"elapsed":4711,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# fs_Hz = 30e3 # Now irrelevant [was: check that this is really true]"],"metadata":{"id":"dhE0YNlGKczu","executionInfo":{"status":"ok","timestamp":1689283985415,"user_tz":420,"elapsed":2,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["fs_Hz = rec.get_sampling_frequency()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjQw96fFN7LN","executionInfo":{"status":"ok","timestamp":1689284757991,"user_tz":420,"elapsed":6,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}},"outputId":"20181844-0007-4072-8bbb-61fd80572bf7"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30000.0"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["This data set is an hour long, so spike sorting can take many hours. For the purposes of this tutorial, we will work with a subset of the data:"],"metadata":{"id":"X62JpJIkTHrc"}},{"cell_type":"code","source":["rec_sub = rec.frame_slice(start_frame=0.0*fs_Hz, end_frame=5.0*60*fs_Hz) # grab 5 minutes"],"metadata":{"id":"h78tmntaKH2C","executionInfo":{"status":"ok","timestamp":1689283986915,"user_tz":420,"elapsed":5,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["That's still 6.5 GB of data, so feel free to experiment with an even shorter snippet. However, too short a snippet will make the sorters produce unreliable output."],"metadata":{"id":"anC10E-lTdBJ"}},{"cell_type":"markdown","source":["Choose one of the installed sorters:"],"metadata":{"id":"sBByD_wpTxIC"}},{"cell_type":"code","source":["ss.installed_sorters()"],"metadata":{"id":"ZYZCDQDuTz8-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689284129145,"user_tz":420,"elapsed":206,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}},"outputId":"7cef8ddd-5023-462a-9032-22fe63f039de"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['herdingspikes', 'mountainsort5', 'spykingcircus2', 'tridesclous2']"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["and educate yourself on the available parameters for that sorter:"],"metadata":{"id":"4uKuKCQKT28E"}},{"cell_type":"code","source":["ss.get_default_sorter_params('herdingspikes') # or 'mountainsort5', etc."],"metadata":{"id":"AG5IDSWsT15m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689284145428,"user_tz":420,"elapsed":206,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}},"outputId":"e2c827c8-ff50-4186-ea0f-ceb994384096"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'clustering_bandwidth': 5.5,\n"," 'clustering_alpha': 5.5,\n"," 'clustering_n_jobs': -1,\n"," 'clustering_bin_seeding': True,\n"," 'clustering_min_bin_freq': 16,\n"," 'clustering_subset': None,\n"," 'left_cutout_time': 0.3,\n"," 'right_cutout_time': 1.8,\n"," 'detect_threshold': 20,\n"," 'probe_masked_channels': [],\n"," 'probe_inner_radius': 70,\n"," 'probe_neighbor_radius': 90,\n"," 'probe_event_length': 0.26,\n"," 'probe_peak_jitter': 0.2,\n"," 't_inc': 100000,\n"," 'num_com_centers': 1,\n"," 'maa': 12,\n"," 'ahpthr': 11,\n"," 'out_file_name': 'HS2_detected',\n"," 'decay_filtering': False,\n"," 'save_all': False,\n"," 'amp_evaluation_time': 0.4,\n"," 'spk_evaluation_time': 1.0,\n"," 'pca_ncomponents': 2,\n"," 'pca_whiten': True,\n"," 'freq_min': 300.0,\n"," 'freq_max': 6000.0,\n"," 'filter': True,\n"," 'pre_scale': True,\n"," 'pre_scale_value': 20.0,\n"," 'filter_duplicates': True}"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["It is worth looking at the documentation for the sorter to see what they have to say about the parameters. Especially important are options that allow you to use more than one CPU or GPU core. Also, make sure that your Colab runtime has a GPU and lots of memory.\n","\n","Next, set a destination folder:"],"metadata":{"id":"EdPr2acSUE3X"}},{"cell_type":"code","source":["dst = Path(\"/content/drive/MyDrive\")"],"metadata":{"id":"gvsSChcxUsMX","executionInfo":{"status":"ok","timestamp":1689284335996,"user_tz":420,"elapsed":207,"user":{"displayName":"Daniel Wagenaar","userId":"06728463478657928471"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["and run *one* of the following:"],"metadata":{"id":"C1ILItxBUzB_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"54ece535"},"outputs":[],"source":["sorting_hs = ss.run_sorter(\"herdingspikes\", rec_sub, output_folder=dst / 'res_slp_hs', verbose=True, filter=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8daf2619"},"outputs":[],"source":["sorting_ms = ss.run_sorter(\"mountainsort5\", rec_sub, output_folder=dst / 'res_slp_ms', verbose=True, filter=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5081f40f"},"outputs":[],"source":["sorting_tri = ss.run_sorter(\"tridesclous2\", rec_sub, output_folder=dst / 'res_slp_tri', verbose=True, filter=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9a0b988"},"outputs":[],"source":["sorting_sc2 = ss.run_sorter(\"spykingcircus2\", rec_sub, output_folder=dst / 'res_slp_sc2', verbose=True, filter=False)"]},{"cell_type":"markdown","source":["You may well run into a few errors. That's OK. Resolving those is part of the exercise. But don't bang your head against any brick walls. Ask for help instead!"],"metadata":{"id":"aN7mLlILU6S1"}}]}