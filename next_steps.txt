1. cluster # vs accuracy, varying for different sample sizes as well (keep uniform distribution)
- The coarser the data, the more effect number of clusters has (stronger negative relationship)

2. nonlinear function for temp generation, keep same stdev as linear
- Exponential distribution makes clustering more coarser, probably because higher power exponential functions turn it more of a binary classifier than a continuous relationship
    - high alt vs not as high
    - try playing around with nn architercture? I don't know if that will help though, reconstructed elevation reflects nonlinear temp plot pretty well
- try other nonlinear funcs?

3. how to structure neural net based on only cause and effect, don't know ground truth?
- QUESTION: where exactly in the CDE process does the NN come in? Last explanation of CFL didn't include a NN
- need to play around with different temp generation functions, giving different Y, X stays same

4. change CFL library code to run without venv < still need to do this
- import old library versions within CFL library or update all uses of functions?
    - first option probably a lot easier, sifting through entire repo will not be fun

MEETING 2:

5. Why does coarser data require finer clustering? Check lower clusters numbers (in between 10 and 100)
- Check clusters averages distribution
- suspect something to do with the error terms OR error only goes down at some fraction of total number of points?

6. Show distribution of elevations within all clusters (averages)

7. check for errors in n clusters vs err code
- check for averaging over number of sample numbers - NOT IT

8. Test data vs training data
- Eberhardt will find

9. Pipeline to: given grid size and ground truth function (linear, exp, etc.) and cluster number, get mean abs error

10. think about good plots to show reconstruction