1. cluster # vs accuracy, varying for different sample sizes as well (keep uniform distribution)
- The coarser the data, the more effect number of clusters has (stronger negative relationship)

2. nonlinear function for temp generation, keep same stdev as linear
- Exponential distribution makes clustering more coarser, probably because higher power exponential functions turn it more of a binary classifier than a continuous relationship
    - high alt vs not as high
    - try playing around with nn architercture? I don't know if that will help though, reconstructed elevation reflects nonlinear temp plot pretty well
- try other nonlinear funcs?

3. how to structure neural net based on only cause and effect, don't know ground truth?
- QUESTION: where exactly in the CDE process does the NN come in? Last explanation of CFL didn't include a NN
- need to play around with different temp generation functions, giving different Y, X stays same

4. change CFL library code to run without venv < still need to do this
- import old library versions within CFL library or update all uses of functions?
    - first option probably a lot easier, sifting through entire repo will not be fun

MEETING 2:

5. Why does coarser data require finer clustering? Check lower clusters numbers (in between 10 and 100)
- Check clusters averages distribution
    - Show distribution of elevations within all clusters (averages)
- suspect something to do with the error terms OR error only goes down at some fraction of total number of points?
#########################################################
- Could the mistake be taking the average of each group (further interpolation) and using the reconstruction to calculate error?
    - error function (absolute error from the mean within a group) rewards groups that are as small as possible
    - smaller cluster groups -> less variance and deviation -> error keeps going down until there is only one datapoint per cluster
    - explains why error starts decreasing at a fraction of total data points rather than a set number
    - TLDR: mistake is with error function, so what other way to measure how good the clustering is?
#########################################################
- Check if range within the group is < some number of standard deviations?
- Check distributions against true distribution
- R2 and adjusted R2 metrics

7. Test data vs training data
- Eberhardt will find

8. Pipeline to: given grid size and ground truth function (linear, exp, etc.) and cluster number, get mean abs error

9. think about good plots to show reconstruction


Gradient for each point, in the direction of max increase
generate another map, coloring angles
make graphs look nicer

IMPORTANT: don't use ground truth elevation, use model's prediction for temperature, compare to ground truth templeratre (without error), reconstruct temperature map instead
distribution plots with predicted temperature, x axis changes (try to match the ground truth x axis), should be sort of piecewise with some error

TODO 2/10/2025:
1. make graphs nicer (distributions specifically)
2. fix up cfl github


TODO 2/13/2025
squared error for MAE graph instead, fix legend order, cut off at 150 x axis, change y axis bc squared error, get rid of title
use matplotlib contour to generate estimations, 5 graphs in a row each with their own titles


TODO 3/14/2025
code base - what to do to update all instances of deprecated function?
package code so that it can be a tutorial:
- separate dataset for testing (13, 17, or other prime resolution), use as test error
ways to generalize to more dimensions (what dimensions to add?)

TODO 4/18/2025
cut sq err graph to 30 clusters
get contour maps for 10km @ 10 clusters and 150km @ 5/7 clusters
make tutorial for elevation/temp notebook

